# Real-Time Data Ingestion Pipeline with Kafka and BigQuery

This project demonstrates a real-time streaming data pipeline built using **Python**, **Apache Kafka**, and **Google BigQuery**, containerized with **Docker**.

It simulates a producer that streams JSON events into Kafka and a consumer that ingests those events into BigQuery.

---

## âš™ï¸ Tech Stack
- Python 3.10
- Apache Kafka
- Google BigQuery (via `google-cloud-bigquery`)
- Docker & Docker Compose

---

## ğŸ“ Project Structure

. â”œâ”€â”€ producer.py # Sends mock data to Kafka â”œâ”€â”€ consumer.py # Reads from Kafka and inserts to BigQuery â”œâ”€â”€ main.py # Optional unified consumer logic â”œâ”€â”€ utils/ â”‚ â””â”€â”€ bigquery_writer.py # Helper for BigQuery insertion â”œâ”€â”€ requirements.txt â”œâ”€â”€ dockerfile â”œâ”€â”€ docker-compose.yml â”œâ”€â”€ architecture.png # Architecture diagram â””â”€â”€ README.md

## ğŸ§  Architecture

![Architecture](architecture.png)

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/AbhignaRao97/realtime-ingestion-platform.git
cd realtime-ingestion-platform